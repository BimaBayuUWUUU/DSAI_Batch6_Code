{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Load Librarry**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_validate, KFold, learning_curve\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Load Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_main = 'https://raw.githubusercontent.com/BimaBayuUWUUU/DSAI_Batch6_Code/main/Finpro/data_FP/data_multilabel/Binary_Target_CFeaturesEngineering_Nm_NoDup.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Muat dataset Anda\n",
    "df_main = pd.read_csv(file_path_main)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data Splitting and Scaling**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Split Features and Target**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pisahkan fitur dan target\n",
    "y = df_main.filter(like='nama_industri_encoded_')\n",
    "X = df_main.drop(columns=y.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Scaling Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# Standardisasi fitur\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Split Data Train and Data Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Bagi data menjadi set latih dan set uji\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inisialisasi jumlah kelas\n",
    "num_classes = len(y_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mengubah DataFrame menjadi array numpy\n",
    "y_train = y_train.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mengubah DataFrame menjadi array numpy\n",
    "y_test = y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Check Label Distribution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label counts in training data:\n",
      "Class 1: 531 samples (2.02%)\n",
      "Class 2: 531 samples (2.02%)\n",
      "Class 3: 523 samples (1.99%)\n",
      "Class 4: 531 samples (2.02%)\n",
      "Class 5: 527 samples (2.00%)\n",
      "Class 6: 530 samples (2.01%)\n",
      "Class 7: 527 samples (2.00%)\n",
      "Class 8: 531 samples (2.02%)\n",
      "Class 9: 530 samples (2.01%)\n",
      "Class 10: 510 samples (1.94%)\n",
      "Class 11: 510 samples (1.94%)\n",
      "Class 12: 531 samples (2.02%)\n",
      "Class 13: 525 samples (1.99%)\n",
      "Class 14: 527 samples (2.00%)\n",
      "Class 15: 466 samples (1.77%)\n",
      "Class 16: 526 samples (2.00%)\n",
      "Class 17: 527 samples (2.00%)\n",
      "Class 18: 531 samples (2.02%)\n",
      "Class 19: 521 samples (1.98%)\n",
      "Class 20: 523 samples (1.99%)\n",
      "Class 21: 517 samples (1.96%)\n",
      "Class 22: 440 samples (1.67%)\n",
      "Class 23: 514 samples (1.95%)\n",
      "Class 24: 523 samples (1.99%)\n",
      "Class 25: 519 samples (1.97%)\n",
      "Class 26: 521 samples (1.98%)\n",
      "Class 27: 531 samples (2.02%)\n",
      "Class 28: 529 samples (2.01%)\n",
      "Class 29: 531 samples (2.02%)\n",
      "Class 30: 525 samples (1.99%)\n",
      "Class 31: 531 samples (2.02%)\n",
      "Class 32: 531 samples (2.02%)\n",
      "Class 33: 531 samples (2.02%)\n",
      "Class 34: 512 samples (1.94%)\n",
      "Class 35: 531 samples (2.02%)\n",
      "Class 36: 517 samples (1.96%)\n",
      "Class 37: 530 samples (2.01%)\n",
      "Class 38: 520 samples (1.97%)\n",
      "Class 39: 531 samples (2.02%)\n",
      "Class 40: 352 samples (1.34%)\n",
      "Class 41: 525 samples (1.99%)\n",
      "Class 42: 525 samples (1.99%)\n",
      "Class 43: 530 samples (2.01%)\n",
      "Class 44: 529 samples (2.01%)\n",
      "Class 45: 528 samples (2.01%)\n",
      "Class 46: 531 samples (2.02%)\n",
      "Class 47: 531 samples (2.02%)\n",
      "Class 48: 525 samples (1.99%)\n",
      "Class 49: 522 samples (1.98%)\n",
      "Class 50: 529 samples (2.01%)\n",
      "Class 51: 531 samples (2.02%)\n",
      "Class 52: 531 samples (2.02%)\n",
      "Class 53: 529 samples (2.01%)\n",
      "Class 54: 519 samples (1.97%)\n",
      "Class 55: 531 samples (2.02%)\n",
      "Class 56: 530 samples (2.01%)\n",
      "Class 57: 531 samples (2.02%)\n",
      "Class 58: 526 samples (2.00%)\n",
      "Class 59: 527 samples (2.00%)\n",
      "Class 60: 519 samples (1.97%)\n",
      "Class 61: 531 samples (2.02%)\n",
      "Class 62: 529 samples (2.01%)\n",
      "Class 63: 520 samples (1.97%)\n",
      "Class 64: 531 samples (2.02%)\n",
      "Class 65: 531 samples (2.02%)\n",
      "Class 66: 531 samples (2.02%)\n",
      "Class 67: 531 samples (2.02%)\n",
      "Class 68: 526 samples (2.00%)\n",
      "Class 69: 518 samples (1.97%)\n",
      "Class 70: 520 samples (1.97%)\n",
      "Class 71: 527 samples (2.00%)\n",
      "Class 72: 505 samples (1.92%)\n",
      "Class 73: 531 samples (2.02%)\n",
      "Class 74: 525 samples (1.99%)\n",
      "Class 75: 521 samples (1.98%)\n"
     ]
    }
   ],
   "source": [
    "# Menghitung jumlah total sampel\n",
    "total_samples = len(y_train)\n",
    "\n",
    "# Menghitung jumlah sampel untuk setiap kelas\n",
    "label_counts = np.sum(y, axis=0)\n",
    "\n",
    "# Menampilkan jumlah sampel untuk setiap kelas\n",
    "print(\"Label counts in training data:\")\n",
    "for i, count in enumerate(label_counts):\n",
    "    class_name = f\"Class {i+1}\"\n",
    "    percentage = (count / total_samples) * 100\n",
    "    print(f\"{class_name}: {count} samples ({percentage:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Modelling With Hyperparameter Tuning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Extreme Gradient Boosting Multi-Label Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter default XGBoostClassifier:\n",
      "objective: binary:logistic\n",
      "base_score: None\n",
      "booster: None\n",
      "callbacks: None\n",
      "colsample_bylevel: None\n",
      "colsample_bynode: None\n",
      "colsample_bytree: None\n",
      "device: None\n",
      "early_stopping_rounds: None\n",
      "enable_categorical: False\n",
      "eval_metric: None\n",
      "feature_types: None\n",
      "gamma: None\n",
      "grow_policy: None\n",
      "importance_type: None\n",
      "interaction_constraints: None\n",
      "learning_rate: None\n",
      "max_bin: None\n",
      "max_cat_threshold: None\n",
      "max_cat_to_onehot: None\n",
      "max_delta_step: None\n",
      "max_depth: None\n",
      "max_leaves: None\n",
      "min_child_weight: None\n",
      "missing: nan\n",
      "monotone_constraints: None\n",
      "multi_strategy: None\n",
      "n_estimators: None\n",
      "n_jobs: None\n",
      "num_parallel_tree: None\n",
      "random_state: None\n",
      "reg_alpha: None\n",
      "reg_lambda: None\n",
      "sampling_method: None\n",
      "scale_pos_weight: None\n",
      "subsample: None\n",
      "tree_method: None\n",
      "validate_parameters: None\n",
      "verbosity: None\n"
     ]
    }
   ],
   "source": [
    "# Inisialisasi model\n",
    "xgboost = XGBClassifier(tree_method=\"hist\", device=\"cuda\")\n",
    "\n",
    "# Mendapatkan parameter default\n",
    "paramsXgb = xgboost.get_params()\n",
    "\n",
    "# Mencetak parameter default\n",
    "print(\"Parameter default XGBoostClassifier:\")\n",
    "for param, value in paramsXgb.items():\n",
    "    print(f\"{param}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter terbaik yang ditemukan:  {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 200, 'subsample': 0.8}\n",
      "Skor akurasi terbaik:  0.8826232038610297\n",
      "Akurasi set pengujian dengan parameter terbaik: 0.8840\n",
      "Presisi: 0.9825\n",
      "Recall: 0.8895\n",
      "F1 Score: 0.9337\n"
     ]
    }
   ],
   "source": [
    "# Menginisialisasi XGBClassifier dengan MultiOutputClassifier\n",
    "xgboost = XGBClassifier(tree_method=\"hist\", device=\"cuda\")\n",
    "\n",
    "param_grid_xgb = {\n",
    "    'learning_rate': [0.01, 0.1, 0.3],\n",
    "    'max_depth': [5, 6, 7],\n",
    "    'n_estimators': [100, 200],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "# Menginisialisasi GridSearchCV\n",
    "grid_search_Xgb = GridSearchCV(estimator=xgboost, param_grid=param_grid_xgb, cv=5, scoring='accuracy')\n",
    "\n",
    "# Melatih model GridSearchCV\n",
    "grid_search_Xgb.fit(X_train, y_train)\n",
    "\n",
    "# Mendapatkan parameter terbaik dan skor terbaik\n",
    "print(\"Parameter terbaik yang ditemukan: \", grid_search_Xgb.best_params_)\n",
    "print(\"Skor akurasi terbaik: \", grid_search_Xgb.best_score_)\n",
    "\n",
    "# Mengevaluasi model terbaik pada set pengujian\n",
    "best_model_Xgb = grid_search_Xgb.best_estimator_\n",
    "y_pred_Xgb = best_model_Xgb.predict(X_test)\n",
    "\n",
    "# Menghitung metrik evaluasi\n",
    "accuraacy_Xgb = accuracy_score(y_test, y_pred_Xgb)\n",
    "precision_Xgb = precision_score(y_test, y_pred_Xgb, average='micro')\n",
    "recall_Xgb = recall_score(y_test, y_pred_Xgb, average='micro')\n",
    "f1_Xgb = f1_score(y_test, y_pred_Xgb, average='micro')\n",
    "\n",
    "# Menampilkan metrik evaluasi\n",
    "print(f\"Akurasi set pengujian dengan parameter terbaik: {accuraacy_Xgb:.4f}\")\n",
    "print(f\"Presisi: {precision_Xgb:.4f}\")\n",
    "print(f\"Recall: {recall_Xgb:.4f}\")\n",
    "print(f\"F1 Score: {f1_Xgb:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Adaptive Boosting Multi-Label Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter default AdaBoostClassifier:\n",
      "algorithm: SAMME.R\n",
      "estimator: None\n",
      "learning_rate: 1.0\n",
      "n_estimators: 50\n",
      "random_state: None\n"
     ]
    }
   ],
   "source": [
    "# Inisialisasi model\n",
    "ada = AdaBoostClassifier()\n",
    "\n",
    "# Mendapatkan parameter default\n",
    "paramsAda = ada.get_params()\n",
    "\n",
    "# Mencetak parameter default\n",
    "print(\"Parameter default AdaBoostClassifier:\")\n",
    "for param, value in paramsAda.items():\n",
    "    print(f\"{param}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter terbaik yang ditemukan:  {'estimator__algorithm': 'SAMME.R', 'estimator__estimator': DecisionTreeClassifier(max_depth=2), 'estimator__learning_rate': 0.1, 'estimator__n_estimators': 200}\n",
      "Skor akurasi terbaik:  0.8754461400412792\n",
      "Akurasi set pengujian dengan parameter terbaik: 0.8748\n",
      "Precision: 0.9898\n",
      "Recall: 0.8756\n",
      "F1 Score: 0.9260\n"
     ]
    }
   ],
   "source": [
    "# Inisialisasi model\n",
    "adaboost = MultiOutputClassifier(AdaBoostClassifier(), n_jobs=-1)\n",
    "\n",
    "# Mendefinisikan parameter grid untuk pencarian\n",
    "param_grid_adb = {\n",
    "    'estimator__n_estimators': [50, 100, 200],\n",
    "    'estimator__learning_rate': [0.01, 0.1, 1.0],\n",
    "    'estimator__estimator': [DecisionTreeClassifier(max_depth=1), DecisionTreeClassifier(max_depth=2), None],\n",
    "    'estimator__algorithm': ['SAMME', 'SAMME.R']\n",
    "}\n",
    "\n",
    "# Menginisialisasi GridSearchCV\n",
    "grid_search_Ada = GridSearchCV(estimator=adaboost, param_grid=param_grid_adb, cv=5, scoring='accuracy')\n",
    "\n",
    "# Melatih model GridSearchCV\n",
    "grid_search_Ada.fit(X_train, y_train)\n",
    "\n",
    "# Mendapatkan parameter terbaik dan skor terbaik\n",
    "print(\"Parameter terbaik yang ditemukan: \", grid_search_Ada.best_params_)\n",
    "print(\"Skor akurasi terbaik: \", grid_search_Ada.best_score_)\n",
    "\n",
    "# Mengevaluasi model terbaik pada set pengujian\n",
    "best_model_Ada = grid_search_Ada.best_estimator_\n",
    "y_pred_Ada = best_model_Ada.predict(X_test)\n",
    "\n",
    "# Menghitung metrik evaluasi\n",
    "accuracy_Ada = accuracy_score(y_test, y_pred_Ada)\n",
    "precision_Ada  = precision_score(y_test, y_pred_Ada, average='macro')\n",
    "recall_Ada  = recall_score(y_test, y_pred_Ada, average='macro')\n",
    "f1_Ada  = f1_score(y_test, y_pred_Ada, average='macro')\n",
    "\n",
    "# Menampilkan metrik evaluasi\n",
    "print(f\"Akurasi set pengujian dengan parameter terbaik: {accuracy_Ada:.4f}\")\n",
    "print(f\"Precision: {precision_Ada:.4f}\")\n",
    "print(f\"Recall: {recall_Ada:.4f}\")\n",
    "print(f\"F1 Score: {f1_Ada :.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Model Evaluation With Cross Validation**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
